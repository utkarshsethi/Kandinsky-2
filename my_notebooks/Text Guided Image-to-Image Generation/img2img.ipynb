{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ai-forever/diffusers.git\n",
    "!pip install transformers\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from diffusers import KandinskyV22PriorEmb2EmbPipeline, KandinskyV22ControlnetImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_image(\n",
    "    \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main\" \"/kandinskyv22/cat.png\"\n",
    ").resize((768, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hint(image, depth_estimator):\n",
    "    image = depth_estimator(image)[\"depth\"]\n",
    "    image = np.array(image)\n",
    "    image = image[:, :, None]\n",
    "    image = np.concatenate([image, image, image], axis=2)\n",
    "    detected_map = torch.from_numpy(image).float() / 255.0\n",
    "    hint = detected_map.permute(2, 0, 1)\n",
    "    return hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_estimator = pipeline(\"depth-estimation\")\n",
    "hint = make_hint(img, depth_estimator).unsqueeze(0).half().to(\"cuda\")\n",
    "\n",
    "pipe_prior = KandinskyV22PriorEmb2EmbPipeline.from_pretrained(\n",
    "    \"kandinsky-community/kandinsky-2-2-prior\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe_prior = pipe_prior.to(\"cuda\")\n",
    "\n",
    "pipe = KandinskyV22ControlnetImg2ImgPipeline.from_pretrained(\n",
    "    \"kandinsky-community/kandinsky-2-2-controlnet-depth\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"A robot, 4k photo\"\n",
    "negative_prior_prompt = \"lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature\"\n",
    "\n",
    "# generator = torch.Generator(device=\"cuda\").manual_seed(43)\n",
    "generator = torch.Generator(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run prior pipeline\n",
    "\n",
    "img_emb = pipe_prior(prompt=prompt, image=img, strength=0.85, generator=generator)\n",
    "negative_emb = pipe_prior(prompt=negative_prior_prompt, image=img, strength=1, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run controlnet img2img pipeline\n",
    "images = pipe(\n",
    "    image=img,\n",
    "    strength=0.5,\n",
    "    image_embeds=img_emb.image_embeds,\n",
    "    negative_image_embeds=negative_emb.image_embeds,\n",
    "    hint=hint,\n",
    "    num_inference_steps=50,\n",
    "    generator=generator,\n",
    "    height=768,\n",
    "    width=768,\n",
    ").images\n",
    "\n",
    "images[0].save(\"robot_cat.png\")\n",
    "images[0]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
